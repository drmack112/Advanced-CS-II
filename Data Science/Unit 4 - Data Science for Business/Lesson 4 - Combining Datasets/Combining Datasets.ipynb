{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: More Books, Please!\n",
    "\n",
    "This example demonstrates how to match two different datasets and concatenate them to result in one single dataset.\n",
    "\n",
    "Follow along with the comments in the code. Match the output to the comments and consider the questions as well.\n",
    "\n",
    "1. First, a comparison is made between the two datasets.\n",
    "\n",
    "    - How many entries are in each dataset?\n",
    "\n",
    "    - How many columns are in each dataset?\n",
    "\n",
    "2. There are additional columns in the Goodreads dataset that are not needed. These are dropped.\n",
    "\n",
    "`goodreads.drop([\"bookID\", \"isbn\", \"isbn13\", \"language_code\", \"text_reviews_count\"], axis=1, inplace=True)`\n",
    "\n",
    "3. There are columns that are named differently between the two sets. The names from the Goodreads dataset and renamed to match the names from the Google dataset.\n",
    "`goodreads.rename(columns={\"authors\": \"author\", \"average_rating\": \"rating\", \"num_pages\": \"page_count\", \"ratings_count\": \"voters\", \"publication_date\": \"published_date\"}, inplace=True)`\n",
    "\n",
    "4. A comparison is made again to check that the columns now match.\n",
    "\n",
    "    - Google has one extra column. What do you think might happen when we concatenate these?\n",
    "\n",
    "    - Do you think the order of the columns will matter?\n",
    "\n",
    "5. The two datasets are concatenated with the data in Google listed first and the data in Goodreads listed second. The indices are reset so that there are not two different rows that share an index.\n",
    "\n",
    "`google_and_goodreads = pd.concat([google, goodreads]).reset_index()`\n",
    "\n",
    "6. Information about the new concatenated dataset is printed to ensure that everything worked correctly.\n",
    "\n",
    "    - How many entries are there?\n",
    "\n",
    "    - What happened with the price column for the Goodreads data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "google = pd.read_csv (r\"google_books.csv\")\n",
    "goodreads = pd.read_csv (r\"goodreads.csv\")\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "google.drop_duplicates(inplace=True)\n",
    "goodreads.drop_duplicates(inplace=True)\n",
    "\n",
    "# Compare columns from both datasets\n",
    "# How many entries are in each dataset?\n",
    "# How many columns are in each dataset?\n",
    "print(\"Google Dataset\")\n",
    "print(\"-------------------\")\n",
    "print(google.info())\n",
    "print()\n",
    "print()\n",
    "print(\"Goodreads Dataset\")\n",
    "print(\"-------------------\")\n",
    "print(goodreads.info())\n",
    "\n",
    "# Goodreads Dataset - drop the extra columns\n",
    "\n",
    "goodreads.drop([\"bookID\", \"isbn\", \"isbn13\", \"language_code\", \"text_reviews_count\"], axis=1, inplace=True)\n",
    "\n",
    "# Goodreads Dataset - rename columns to match the google dataset\n",
    "\n",
    "goodreads.rename(columns={\"authors\": \"author\", \"average_rating\": \"rating\", \"num_pages\": \"page_count\", \"ratings_count\": \"voters\", \"publication_date\": \"published_date\"}, inplace=True)\n",
    "\n",
    "# Again - compare columns from both datasets\n",
    "# Google has one extra column. What do you think might happen when we concatenate these?\n",
    "# Do you think the order of the columns will matter?\n",
    "print()\n",
    "print()\n",
    "print(\"Google Dataset\")\n",
    "print(\"-------------------\")\n",
    "print(google.info())\n",
    "print()\n",
    "print()\n",
    "print(\"Goodreads Dataset\")\n",
    "print(\"-------------------\")\n",
    "print(goodreads.info())\n",
    "\n",
    "# Concatenate the two datasets (add on as new rows)\n",
    "google_and_goodreads = pd.concat([google, goodreads]).reset_index()\n",
    "print()\n",
    "print()\n",
    "print(\"Google and Goodreads Dataset\")\n",
    "print(\"-------------------\")\n",
    "print(google_and_goodreads)\n",
    "\n",
    "# Check the information from the new concatenated dataset.\n",
    "# How many entries are there?\n",
    "# What happened with the price column for the goodreads data?\n",
    "print()\n",
    "print()\n",
    "print(\"Google and Goodreads Dataset\")\n",
    "print(\"-------------------\")\n",
    "print(google_and_goodreads.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1 - Concatenating Cats\n",
    "\n",
    "The cat shelter uses two different databases - one for male cats and one for female cats. They’d like to combine the two datasets. Complete the following to explore and concatenate the two datasets.\n",
    "\n",
    "1. First, make a comparison between the two datasets.\n",
    "\n",
    "    - How many entries are in each dataset?\n",
    "\n",
    "    - How many columns are in each dataset?\n",
    "\n",
    "    - Are the columns named the same or differently?\n",
    "\n",
    "2. Change the names of the columns so that they match across the two datasets.\n",
    "\n",
    "3. Compare the two datasets again to check that the columns now match.\n",
    "\n",
    "4. Concatenate the two datasets while also resetting the indices.\n",
    "\n",
    "5. Print the information about the new concatenated dataset to ensure that everything worked correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "male = pd.read_csv (r\"male_cats.csv\")\n",
    "female = pd.read_csv (r\"female_cats.csv\")\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "\n",
    "# Compare columns from both datasets\n",
    "print(\"Male Cats\")\n",
    "print(\"-------------------\")\n",
    "\n",
    "\n",
    "print()\n",
    "print()\n",
    "print(\"Female Cats\")\n",
    "print(\"-------------------\")\n",
    "\n",
    "\n",
    "\n",
    "# Rename columns to match across both datasets\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Again - compare columns from both datasets\n",
    "\n",
    "print(\"Male Cats\")\n",
    "print(\"-------------------\")\n",
    "\n",
    "\n",
    "print()\n",
    "print()\n",
    "print(\"Female Cats\")\n",
    "print(\"-------------------\")\n",
    "\n",
    "\n",
    "\n",
    "# Concatenate the two datasets (add on as new rows)\n",
    "\n",
    "print()\n",
    "print()\n",
    "print(\"All Cats\")\n",
    "print(\"-------------------\")\n",
    "\n",
    "\n",
    "# Check the information from the new concatenated dataset.\n",
    "print()\n",
    "print()\n",
    "print(\"Google and Goodreads Dataset\")\n",
    "print(\"-------------------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Filling in Gaps\n",
    "\n",
    "A grocery store has been collecting data about its customers and their purchases. Some of the data is collected using the cash register receipts and more data is collected using an optional online survey that the customers fill out themselves.\n",
    "\n",
    "This example demonstrates the four different ways of combining and joining the two datasets.\n",
    "\n",
    "Follow along with the comments in the code. Match the output to the comments and consider the questions as well.\n",
    "\n",
    "1. The data is printed for both datasets to compare them.\n",
    "\n",
    "    - Are there names that appear in both sets?\n",
    "\n",
    "2. First, an inner join is used is combine the two datasets using the last_name column as the primary key.\n",
    "\n",
    "    - What was kept?\n",
    "\n",
    "    - Do you notice any duplicate columns? Why do think this happened?\n",
    "\n",
    "3. Next, an outer join was used. This time the first_name AND last_name were used as primary keys.\n",
    "\n",
    "    - What was kept?\n",
    "\n",
    "    - What do the NaN values represent?\n",
    "\n",
    "4. Next, a left join was used to combine the two datasets.\n",
    "\n",
    "    - What was kept?\n",
    "\n",
    "    - What do the NaN values represent?\n",
    "\n",
    "5. Lastly, a right join was used to combine the two datasets.\n",
    "\n",
    "    - What was kept?\n",
    "\n",
    "    - What do the NaN values represent?\n",
    "\n",
    "6. Which join might make the most sense to use and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv(r\"customers1.csv\")\n",
    "df2 = pd.read_csv(r\"customers2.csv\")\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# Print both datasets for comparison\n",
    "# Are there names that appear in both sets?\n",
    "print(\"DF1\")\n",
    "print(\"----------\")\n",
    "print(df1)\n",
    "print()\n",
    "print()\n",
    "print(\"DF2\")\n",
    "print(\"----------\")\n",
    "print(df2)\n",
    "\n",
    "# Inner Join using the last_name as a primary key\n",
    "# What was kept?\n",
    "# Do you notice any duplicate columns? Why do think this happened?\n",
    "print()\n",
    "print()\n",
    "print(\"Inner Join\")\n",
    "print(\"----------\")\n",
    "print(pd.merge(df1, df2, on=\"last_name\", how=\"inner\"))\n",
    "\n",
    "# Outer Join using the first_name AND last_name as primary keys\n",
    "# What was kept?\n",
    "# What do the NaN values represent?\n",
    "print()\n",
    "print()\n",
    "print(\"Outer Join\")\n",
    "print(\"----------\")\n",
    "print(pd.merge(df1, df2, on=[\"first_name\",\"last_name\"], how=\"outer\"))\n",
    "\n",
    "# Left Join using the first_name AND last_name as primary keys\n",
    "# What was kept?\n",
    "# What do the NaN values represent?\n",
    "print()\n",
    "print()\n",
    "print(\"Left Join\")\n",
    "print(\"----------\")\n",
    "print(pd.merge(df1, df2, on=[\"first_name\",\"last_name\"], how=\"left\"))\n",
    "\n",
    "# Right Join using the first_name AND last_name as primary keys\n",
    "# What was kept?\n",
    "# What do the NaN values represent?\n",
    "print()\n",
    "print()\n",
    "print(\"Right Join\")\n",
    "print(\"----------\")\n",
    "print(pd.merge(df1, df2, on=[\"first_name\",\"last_name\"], how=\"right\"))\n",
    "\n",
    "# Which join might make the most sense to use and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2 - School Nurse\n",
    "\n",
    "A nurse visits a small school twice a year. While he is there, he takes the height and weight of each student. However, there are often students absent when he visits.\n",
    "\n",
    "Listed in this activity are the two datasets that resulted from the nurse’s two visits. The roster has changed from his first visit (first.csv) to his second visit (second.csv). The current roster of students can be found in the second file.\n",
    "\n",
    "How can we keep all of the students in the second roster but add in missing information that might be found in the first roster?\n",
    "\n",
    "1. Look at the two datasets. Which column (or columns) should act as the primary key(s)?\n",
    "\n",
    "2. Which join method will keep the students found in the second roster and add on missing information found in the first roster?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3 - Coding for Real Estate Data\n",
    "Max is a data scientist who works to gather and combine different real estate datasets and make them available all in one place.\n",
    "\n",
    "1. Max uses Python but also mentioned a lot of other programs and languages. Choose one to briefly research and jot down what you found in the following free-response item.\n",
    "\n",
    "2. At the end of this article, Max recommends talking with industry experts before starting a project. Why do you think this is important?\n",
    "\n",
    "[https://drive.google.com/file/d/1-9xioCTN9qzkf8qJRycQhHYU0f5gvCpd/view?usp=sharing](https://drive.google.com/file/d/1-9xioCTN9qzkf8qJRycQhHYU0f5gvCpd/view?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#answers"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
