{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Books Quality\n",
    "\n",
    "Read through the comments and take note of the different functions used to find out more about this dataset.\n",
    "\n",
    "Is this dataset of good quality? Why or why not?\n",
    "\n",
    "Data Source: [https://www.kaggle.com/bilalyussef/google-books-dataset](https://www.kaggle.com/bilalyussef/google-books-dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.5 64-bit ('base': conda)' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: 'conda install -n base ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Click on the Example tab to see more info. -->\n",
    "# <-- Click on the data.csv file to see the dataset.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "google_books_df = pd.read_csv (r\"google_books.csv\")\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "print(\"Number of null values for each column:\")\n",
    "print(\"----------------------------------------\")\n",
    "print(google_books_df.isnull().sum())\n",
    "\n",
    "print()\n",
    "print(\"Mean (Average) of null values in each column:\")\n",
    "print(\"----------------------------------------\")\n",
    "print(google_books_df.isnull().mean())\n",
    "\n",
    "print()\n",
    "print(\"Percentage of null values in each column:\")\n",
    "print(\"----------------------------------------\")\n",
    "print(google_books_df.isnull().mean())\n",
    "\n",
    "print()\n",
    "print(\"Mean (Average) of null values in the WHOLE dataset:\")\n",
    "print(\"----------------------------------------\")\n",
    "print(google_books_df.isnull().mean().mean())\n",
    "\n",
    "print()\n",
    "print(\"Percentage of null values in the WHOLE dataset:\")\n",
    "print(\"----------------------------------------\")\n",
    "print(google_books_df.isnull().mean().mean())\n",
    "\n",
    "print()\n",
    "print(\"Number of duplicated rows in the datset:\")\n",
    "print(\"----------------------------------------\")\n",
    "print(google_books_df.duplicated().sum())\n",
    "\n",
    "# Drops the duplicated rows\n",
    "google_books_df.drop_duplicates(inplace=True)\n",
    "\n",
    "print()\n",
    "print(\"Number of duplicated rows after dropping:\")\n",
    "print(\"----------------------------------------\")\n",
    "print(google_books_df.duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Cereal Production Quality\n",
    "\n",
    "This data set provides information about cereal production in metric tons for different countries during different years.\n",
    "\n",
    "Read through the comments and take note of the different functions used to find out more about this dataset.\n",
    "\n",
    "Is this dataset of good quality? Why or why not? How did it compare with the dataset in the last example?\n",
    "\n",
    "Data Source: [https://data.worldbank.org/indicator/AG.PRD.CREL.MT?most_recent_value_desc=true](https://data.worldbank.org/indicator/AG.PRD.CREL.MT?most_recent_value_desc=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click on the Example tab to see more info. -->\n",
    "# <-- Click on the cereal.csv file to see the dataset.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "cereal_df = pd.read_csv (r\"cereal.csv\")\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "print(\"Number of null values for each column:\")\n",
    "print(\"----------------------------------------\")\n",
    "print(cereal_df.isnull().sum())\n",
    "\n",
    "print()\n",
    "print(\"Mean of null values in each column:\")\n",
    "print(\"----------------------------------------\")\n",
    "print(cereal_df.isnull().mean())\n",
    "\n",
    "print()\n",
    "print(\"Percentage of null values in each column:\")\n",
    "print(\"----------------------------------------\")\n",
    "print(cereal_df.isnull().mean().round(4) * 100)\n",
    "\n",
    "print()\n",
    "print(\"Mean of null values in the WHOLE dataset:\")\n",
    "print(\"----------------------------------------\")\n",
    "print(cereal_df.isnull().mean().mean())\n",
    "\n",
    "print()\n",
    "print(\"Percentage of null values in the WHOLE dataset:\")\n",
    "print(\"----------------------------------------\")\n",
    "print(cereal_df.isnull().mean().mean().round(4) * 100)\n",
    "\n",
    "print()\n",
    "print(\"Number of duplicated rows in the datset:\")\n",
    "print(\"----------------------------------------\")\n",
    "print(cereal_df.duplicated().sum())\n",
    "\n",
    "# Drops the duplicated rows\n",
    "cereal_df.drop_duplicates(inplace=True)\n",
    "\n",
    "print()\n",
    "print(\"Number of duplicated rows after dropping:\")\n",
    "print(\"----------------------------------------\")\n",
    "print(cereal_df.duplicated().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1 - Determining Completeness\n",
    "\n",
    "The datasets used in the course until now have been previously cleaned in some way to make learning the material less difficult.\n",
    "\n",
    "In this activity, the raw datasets (without any cleaning) are provided. Your task is to check the completeness of at least two different datasets to compare and contrast them.\n",
    "\n",
    "Are you able to determine which set has the best completeness? The worst?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click on the Assignment tab to see more info. -->\n",
    "# <-- Click on the files to see the different datasets.\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Completeness Reflection\n",
    "\n",
    "Answer the following questions based on the information learned in the last activity.\n",
    "\n",
    "1. Of the datasets that you explored, which had the highest level of completeness? How are you determining this?\n",
    "\n",
    "2. Of the datasets that you explored, which had the lowest level of completeness? How are you determining this?\n",
    "\n",
    "3. Name at least one thing you found interesting about being able to view the raw data files.\n",
    "\n",
    "4. How do you think a data source can improve its dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Fuzzy Matching\n",
    "\n",
    "Read through the comments and take note of the different functions used to determine if there are values that need to be renamed.\n",
    "\n",
    "Data Source: [https://www.kaggle.com/bilalyussef/google-books-dataset](https://www.kaggle.com/bilalyussef/google-books-dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import process, fuzz\n",
    "\n",
    "df = pd.read_csv (r\"data.csv\")\n",
    "\n",
    "# Create a Series of unique author names\n",
    "new_table = df[\"author\"].unique()\n",
    "\n",
    "# Extract values that are close to matching \n",
    "matches = process.extract(\"Agatha Christie\", new_table, limit=6)\n",
    "\n",
    "# Print out each matching item\n",
    "print()\n",
    "for item in matches:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2 - Fuzzy Book Titles\n",
    "\n",
    "In this activity, use FuzzyWuzzy to extract all titles that are close to matching the word “batman”.\n",
    "\n",
    "Print out the results. Are they unique book titles or do you notice errors in the titles?\n",
    "\n",
    "Data Source: [https://www.kaggle.com/bilalyussef/google-books-dataset](https://www.kaggle.com/bilalyussef/google-books-dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import process, fuzz\n",
    "\n",
    "df = pd.read_csv (r\"data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Renaming Values\n",
    "\n",
    "Run the code to review the FuzzyWuzzy matches.\n",
    "\n",
    "Uncomment the lines of code in the multi-line code block and rerun the code.\n",
    "\n",
    "`df.author.replace(to_replace =[\"agatha Christie\", \"AgathaChristie\", \"Agath Christie\", \"Agathachristie\", \"Christie Agatha\"], value = \"Agatha Christie\", inplace=True)`\n",
    "\n",
    "How is the result different? Has the fuzzy matches been fixed?\n",
    "\n",
    "Data Source: [https://www.kaggle.com/bilalyussef/google-books-dataset](https://www.kaggle.com/bilalyussef/google-books-dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import process, fuzz\n",
    "\n",
    "df = pd.read_csv (r\"data.csv\")\n",
    "\n",
    "# Uncomment the following command to fix the fuzzy matches\n",
    "\"\"\"\n",
    "df.author.replace(to_replace =[\"agatha Christie\", \"AgathaChristie\", \"Agath Christie\", \"Agathachristie\", \"Christie Agatha\"], value = \"Agatha Christie\", inplace=True)\n",
    "\"\"\"\n",
    "\n",
    "# Create a Series of unique author names\n",
    "new_table = df[\"author\"].unique()\n",
    "\n",
    "# Extract values that are close to matching \n",
    "matches = process.extract(\"Agatha Christie\", new_table, limit=6)\n",
    "\n",
    "# Print out each matching item\n",
    "print()\n",
    "for item in matches:\n",
    "    print(item)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3 - Fix the Book Titles\n",
    "\n",
    "Copy over your code from the **Fuzzy Book Titles** exercise. Use the results of the FuzzyWuzzy extract function to determine which titles need to be changed for consistancy.\n",
    "\n",
    "Use the replace function to change the incorrect titles to match the desired titles.\n",
    "\n",
    "Data Source: [https://www.kaggle.com/bilalyussef/google-books-dataset](https://www.kaggle.com/bilalyussef/google-books-dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import process, fuzz\n",
    "\n",
    "df = pd.read_csv (r\"data.csv\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ed225720166559e7176d3793db16a2fd8d295f725007103b21ac3099d2a89ee8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
